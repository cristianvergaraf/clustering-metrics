{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "electoral-appearance",
   "metadata": {},
   "source": [
    "# Script para la generacion de una columna con la asignacion de codigo de uso del suelo para cada shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appointed-bibliography",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informative-toronto",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path =(r\"C:/projectos/shapes/\")\n",
    "# Change the directory\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dying-hindu",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Guardar los archivos en un diccionario indicando el nombre del arhivo \n",
    "## en la clave\n",
    "\n",
    "dict_shapes = {}\n",
    "\n",
    "# Iterate over all the files in the directory\n",
    "for file in os.listdir():\n",
    "   if file.endswith('.shp') and file[0].isalpha():\n",
    "       temp = gpd.read_file(file)\n",
    "       dict_shapes[file] = temp\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-broadcast",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vamos a verificar el contenido del diccionario\n",
    "\n",
    "#dict_shapes['Albacete_class.shp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-welsh",
   "metadata": {},
   "source": [
    "Definir una funcion para agragar un columna con el codigo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def merge_shape(data_in,data_out):\n",
    "    for keys, values in data_in.items():\n",
    "        data_in[keys] = data_in[keys].reset_index()\n",
    "        USOS = data_in[keys].USO.unique()\n",
    "        cod_usos = np.arange(1,len(USOS)+1)\n",
    "        df_cod_usos = pd.DataFrame({'USO':USOS, \"cod_usos\":cod_usos})\n",
    "        data_out[keys]= pd.merge(data_in[keys], df_cod_usos, on ='USO', how = \"left\")\n",
    "    return(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "multiple-mediterranean",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def asignacion_codigo_categorias_chatgtp(data_in):\n",
    "    data_out = {}\n",
    "    for key, df in data_in.items():\n",
    "        df = df.reset_index()\n",
    "        usos = df['USO'].unique()\n",
    "        cod_usos = np.arange(len(usos))\n",
    "        cod_map = pd.Series(cod_usos, index=usos)\n",
    "        df['cod_usos'] = df['USO'].map(cod_map)\n",
    "        data_out[key] = df\n",
    "    return data_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "occupational-effectiveness",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ciudades_codigo = asignacion_codigo_categorias_chatgtp(dict_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alone-williams",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ciudades_codigo['Albacete_class.shp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "reasonable-haiti",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for keys, values in ciudades_codigo.items():\n",
    "    ciudades_codigo[keys].to_file('C:/projectos/shapes/asignacion/'+ keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-rebel",
   "metadata": {},
   "source": [
    "## Revision de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "textile-transformation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_shapes = []\n",
    "\n",
    "# Iterate over all the files in the directory\n",
    "for file in os.listdir():\n",
    "   if file.endswith('.shp') and file[0].isalpha():\n",
    "        number_shapes.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "separate-worthy",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(number_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "impressed-drive",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albacete_class.shp', 'Alcala_class.shp', 'Alcobendas_class.shp', 'Alcorcon_class.shp', 'Algeciras.shp', 'Alicante_class.shp', 'Almeria_class.shp', 'Avila_class.shp', 'Badajoz_class.shp', 'Badalona_class.shp', 'Barcelona_class.shp', 'Burgos_class.shp', 'Caceres_class.shp', 'Cadiz_class 2.shp', 'Cadiz_class.shp', 'Cartagena_class.shp', 'Castello_de_la_Plana_class.shp', 'Ceuta_class.shp', 'Ciudad_Real_class.shp', 'Cordoba_class.shp', 'Corunia_class.shp', 'Cuenca_class.shp', 'doshermanas_class.shp', 'Elche_class.shp', 'Fuenlabrada_class.shp', 'Getafe.shp', 'Gijon_class.shp', 'Girona_class.shp', 'Granada_class.shp', 'Guadalajara_class.shp', 'Hospitalet_de_Llobregat_class.shp', 'Huelva_class.shp', 'Huesca_class.shp', 'Jaen_class.shp', 'Jerez_de_la_Frontera_class.shp', 'Las_Palmas_Gran_Canaria_class.shp', 'Leganes.shp', 'Leon_class.shp', 'Lleida_class.shp', 'Logronio_class.shp', 'Lugo_class.shp', 'Madrid_class.shp', 'Malaga_class.shp', 'Marbella_class.shp', 'Mataro_clas.shp', 'Melilla_class.shp', 'Mostoles_class.shp', 'Murcia_class.shp', 'Ourense_class.shp', 'Oviedo_class.shp', 'Palencia_class.shp', 'Palma_class.shp', 'Parla_clas.shp', 'Pontevedra_class.shp', 'Sabadell.shp', 'Salamanca_class.shp', 'Santander_class.shp', 'Santa_Coloma.shp', 'Santa_Cruz_Tenerife_class.shp', 'San_Cristobal_de_la_Laguna_class.shp', 'Segovia_class.shp', 'Sevilla_class.shp', 'Soria_class.shp', 'Tarragona_class.shp', 'Terrasa_clas.shp', 'Teruel_class.shp', 'Toledo_class.shp', 'Torrejon_clas.shp', 'Valencia_class.shp', 'Valladolid_class.shp', 'Vigo_class.shp', 'Zamora_class.shp', 'Zaragoza_class.shp']\n"
     ]
    }
   ],
   "source": [
    "path =(r\"C:/projectos/shapes/marcos_clasificacion/\")\n",
    "# Change the directory\n",
    "os.chdir(path)\n",
    "number_shapes = []\n",
    "\n",
    "# Iterate over all the files in the directory\n",
    "for file in os.listdir():\n",
    "   if file.endswith('.shp') and file[0].isalpha():\n",
    "        number_shapes.append(file)\n",
    "\n",
    "print(number_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "extraordinary-repeat",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "Unable to open Cadiz_class 2.shx or Cadiz_class 2.SHX. Set SHAPE_RESTORE_SHX config option to YES to restore or create it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mfiona\\ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: Unable to open Cadiz_class 2.shx or Cadiz_class 2.SHX. Set SHAPE_RESTORE_SHX config option to YES to restore or create it.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir():\n\u001b[0;32m      9\u001b[0m    \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.shp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39misalpha():\n\u001b[1;32m---> 10\u001b[0m        temp \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(file)\n\u001b[0;32m     11\u001b[0m        dict_shapes[file] \u001b[38;5;241m=\u001b[39m temp\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\datamecum\\lib\\site-packages\\geopandas\\io\\file.py:259\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m     path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_fiona(\n\u001b[0;32m    260\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    261\u001b[0m     )\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[0;32m    264\u001b[0m         path_or_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    265\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\datamecum\\lib\\site-packages\\geopandas\\io\\file.py:303\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[1;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[1;32m--> 303\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m reader(path_or_bytes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[0;32m    304\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\datamecum\\lib\\site-packages\\fiona\\env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\datamecum\\lib\\site-packages\\fiona\\__init__.py:360\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 360\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    361\u001b[0m         path,\n\u001b[0;32m    362\u001b[0m         mode,\n\u001b[0;32m    363\u001b[0m         driver\u001b[38;5;241m=\u001b[39mdriver,\n\u001b[0;32m    364\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    365\u001b[0m         layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    366\u001b[0m         enabled_drivers\u001b[38;5;241m=\u001b[39menabled_drivers,\n\u001b[0;32m    367\u001b[0m         allow_unsupported_drivers\u001b[38;5;241m=\u001b[39mallow_unsupported_drivers,\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    369\u001b[0m     )\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    371\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    372\u001b[0m         path,\n\u001b[0;32m    373\u001b[0m         mode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    383\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\datamecum\\lib\\site-packages\\fiona\\collection.py:234\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[1;32mfiona\\ogrext.pyx:587\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: Unable to open Cadiz_class 2.shx or Cadiz_class 2.SHX. Set SHAPE_RESTORE_SHX config option to YES to restore or create it."
     ]
    }
   ],
   "source": [
    "# Vamos a leer los datos shapes y guardarlos en un diccionario\n",
    "\n",
    "## Guardar esto en un diccionario\n",
    "\n",
    "dict_shapes = {}\n",
    "\n",
    "# Iterate over all the files in the directory\n",
    "for file in os.listdir():\n",
    "   if file.endswith('.shp') and file[0].isalpha():\n",
    "       temp = gpd.read_file(file)\n",
    "       dict_shapes[file] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "agricultural-kansas",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albacete_class.shp\n",
      "Alcala_class.shp\n",
      "Alcobendas_class.shp\n",
      "Alcorcon_class.shp\n",
      "Algeciras.shp\n",
      "Alicante_class.shp\n",
      "Almeria_class.shp\n",
      "Avila_class.shp\n",
      "Badajoz_class.shp\n",
      "Badalona_class.shp\n",
      "Barcelona_class.shp\n",
      "Burgos_class.shp\n",
      "Caceres_class.shp\n"
     ]
    }
   ],
   "source": [
    "for key, value in dict_shapes.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-sucking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
